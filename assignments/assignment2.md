# Assignment 2 CSE 221
Jules Testard

## Part 1 : GMS DesignIn the GMS paper, only "clean" pages are written to global memory ("dirty" pages must be written to disk before they can participate in the GMS pool).
##### 1) Why did GMS chose this restriction? What problem does it solve?
This restriction means that any page in global memory is expendable. If a node crashes, then the contents of the memory of this node can be recreated from disk. If we allowed dirty pages in global memory, then in the events of a crash the changes on that page would be lost forever.

The other advantage is in the case where the same page exists on two nodes at the same time (shared pages). If we allow writes to that page, then if a write occured on node A, the copy of the page on node B would need to be updated. No such work is required as long as pages are clean.

Finally, if a page is clean and is sent to be written to disk by the GMS, it can be discarded instead.##### 2) Describe how you might change GMS to safely allow it to write dirty pages to global memory.I would advise against it, but if it needed to be done we would need to :
 - Write the global page to disk whenever it is made dirty, to ensure contents cannot be lost even in case of a crash.
 - Propagate any write made to disk to all copies of that page, to ensure all copies of the same page are identical at all times.

Needless to say, this would be very expensive for a marginal gain.##### 1) Why does GMS require trusted nodes? What risks would be exposed by an untrusted node?
Individual nodes rely on other nodes in the cluster to follow the GMS algorithm. If one node decides not to follow the GMS behaviour when an action occurs, this can have dramatic consequences. For example, if a node decides to lie on its age of its pages when it sends that information to the initiator node, it could trigger an extremely high number of epochs or force all evictions to occur on its own node, slowing the system excessively. A malicious node could also corrupt its global memory, making the corrupt pages unusable for nodes in the system which need them.
##### 2) Describe how you might change GMS to work with untrusted nodes?If GMS is to work with untrusted nodes, then any information (such as page content or page age) sent to other nodes (such as global page content and time information) needs to be encrypted. Any information retrieved from other nodes must be decrypted accordingly.## Part 2 : Transparency vs optimization
Butler Lampson once gave a set of principles for system design. Among these, he gave two conflicting pieces of advice on the nature of implementations. He said, "Keep secrets of the implementation. Secrets are assumptions about an implementation that client programs are not allowed to make... Obviously, it is easier to program and modify a system if its parts make fewer assumptions about each other." And yet, "One way to improve performance is to increase the number of assumptions that one part of a system makes about another; the additional assumptions often allow less work to be done, sometimes a lot less." That is, on the one hand we should hide an implementation for ease of development (transparency), and, on the other, we should expose our implementations for speed (optimization).Consider this issue for each of the following three systems ­­ Sprite, Xen, Grapevine. For each system:
  1. Which advice of Lampson's did the authors follow? That is, describe the service that was implemented, and whether the authors chose to hide or expose in the implementation.  2. Describe what was hidden or exposed in the implementation, and the software mechanisms that were used to do the hiding or exposing. Be specific.  3. Give a concrete example of how the mechanisms above were used to hide or expose in the system.  4. Describe one problem the authors had in utilizing their mechanism for their respective purpose, and how the authors dealt with that problem. Be specific.  5. Given the quotes above, discuss the authors' goals in following the design principle they chose. Did they achieve them? Justify your answer.### Section 1 : Sprite
**1)** Sprite is a network-oriented operating system which attempts to provide an abstraction to the user that he is communicating with a single giant machine rather than a network of computers. As such, we could say the authors are trying to hide their implementation from the user of the operating system.

**2)** To achieve this goal of transparency, the authors are hiding : - The distributed nature of the file system : any client node in the network is exposed to the same unique large file system as if they were on a single machine. The author use a feature called prefix tables to implement and manage this global file system.
 - The distributed nature of the computation : the operating system may execute a procedure on another workstation in the system if it deems it worthwhile, and the user doesn't have to be aware of this. A simple remote procedure call facility allows locally initialized processes to execute on remote machines.
 - The absence of disks on individual workstations : variable-sized file caches are installed on each node which allows diskless workstations to remain efficient.
 
**3)** To hide the distributed nature of the file system, for example, each node stores locally a prefix table. This table is used to determine if a file is available locally or if it has to be fetch from another node in cluster. In the latter case, the system will use the remote procedure call facility to retrieve the file and serve it to the user.

**4)** One issue arose when a locally cached version of a file was being viewed on one node and edited on another. The solution adopted by the authors was to propagate updates as soon as they happen to other copies of the file in the network.

**5)** The authors achieve their goal of transparency in their (relatively small) setting, but it seems doubtful their system would scale very far, especially if nodes are on different geographical locations. In particular, allowing simultaneous access over a file will become a much harder task.

### Section 2 : Xen

**1)** Xen is a virtualization operating system which allows multiple heterogeneous guest operating systems (GuestOS) to execute simultaneously on the same machine. Their goal is to give the user the illusion he is using the GuestOS as if Xen did not exist. As such, the author try to hide their implementation as much as possible.

**2)** Three main aspects of the operating system are hidden from the user :

 - Memory virtualization : the system is given the illusion it makes its own memory management, but memory page faults are handled by Xen, not the guest OS.
 - CPU virtualization : the GuestOS kernel is given the illusion of having direct control over process scheduling, but in reality it is itself scheduled by Xen. 
 - Device I/O virtualization : the GuestOS will be given the illusion that it can directly access I/O devices, while in reality all GuestOS accesses will go through Xen first.
 
All of these illusions are provided by the hypervisor system, which sits at the highest level of privilege (ring 0). All GuestOS kernels are relegated to ring 1 (rings are an x86 hardware concept which seggregates instruction registers and other things according to privilege level).

**3)** 
Lets take the example of how the CPU is virtualized. The GuestOS kernel itself is given a time slice by the Xen scheduler (located in the hypervisor). When that time slice is up, the hypervisor hangs the current GuestOS and transfers control to the next GuestOS, which is itself given a time slice to execute its operations. One problem which comes with this scheduling method is that GuestOSes rely on a timer to schedule the processor they themselves are running. When execution resumes in a GuestOS, relying on the machine timer would give currently running threads on that OS an inaccurate time spent value. In order to solve that problem, Xen manages an array of timers (one for each GuestOS) which records only the time that OS has spent executing.

**4)** Xen also allows exception handling virtualization by letting GuestOSes register their own exception handlers on the hardware. This allows the GuestOSes to run their exception directly rather than rely on a trap into the Xen hypervisor. One problem is that it is possible for a GuestOS to invoke an exception handler it did not yet register. This situation is never supposed to happen if the GuestOS runs directly on the machine and would lead to a crash of the entire operating system. The author solved this problem by allowing Xen to trap these "double faults", since they can only occur on GuestOS exceptions, not Xen exceptions.

**5)** The authors achieve their goal pretty well, and their virtualization techniques are still use nowadays at giant software companies such as Amazon.

### Section 3 : Grapevine
## Part 3 : Lazy evaluation
When implementing some service a common tradeoff is between "eager evaluation" -- performing an action immediately when it is requested (hopeing to amortize that cost against future accesses) and "lazy evaluation" -- defering the requested action until some later point in time (assuming that it will cost less or may not need to be done in the future). What choice to make depends both on the cost of the operation and the expected workload. For each of the following systems :
 - Mach - Exokernel - Xen - Vax/VMS

Do the following : 
 1. Identify an important operation that uses eager or lazy evaluation as an optimization. - Explain what the operation is and what the required semantics are for it to be correct. - Describe how the implementation is eager or lazy (including any mechanisms used to ensure correctness).  - Describe why this is expected to provide an optimization in the common case.
 - Decribe a workload scenario in which this implementation will not be an optimization. ### Section 1 : Mach
An example of a lazy evaluation strategy used in the Mach operating system is the use of *shadow objects*. When two tasks share an object in memory, instead of providing each task with a copy of the object, Mach allows both tasks to point to the same location in memory. As a long as no tasks reads this object, no other action is necessary (this is the lazy part).
If the page is written to by either task, even then a fully copy of the object isn't created. Instead, a shadow object is created for that task. Shadow objects yet are another form of lazy evaluation. A shadow object is task-specific and a reference to all pages which that task's version of the object. For all pages which were never modified, the shadow object points to the original shared memory object as described earlier. For each page that has been written to by the task, it points to the modified version of that page which is specific to that task.
Shadow objects are an excellent way of saving memory space when multiple tasks point to the same object for workloads where writes mostly affect a small subset of the pages of that object. When a shared object is being intensively written to by multiple tasks and the subset of pages written to is large, then the shadow object becomes an overhead in terms of maintenance and indirection.
### Section 2 : Exokernel
An example of eager evaluation in the Exokernel operating system is the *secure bindings* feature. Exokernel allows library OSes to manage resources, while the kernel is responsible for handling protection between mutually untrusted applications. Protection is an expensive operation, but once an application has been authorized to use a given resource, access checks are no longer required. Therefore, the secure bindings separates *binding* a resource to an application from *accessing* that resource :
*By isolating the need to understand these semantics to bind time, the kernel can efficiently implement access checks at access time without understanding them.*
This type of operation is best when an application continuously uses a resource it has requested authorization for. If an application decides to continuously ask for different resources, more binding checks will be required which removes the benefit of the secure bindings.
### Section 3 : Xen
An example of lazy evaluation in the Xen operating system is GuestOS "fast" exception handler registration. Xen operates on the x86 architecture on ring 0 (highest instruction privilege). Guest OSes which Xen virtualizes operate on ring 1, but their code has been written to function on the highest privilege. As such, Xen has to simulate some registers which are only available on ring 0 to handle exceptions such as segmentation faults and allow Guest OSes to register exception handlers with the hardware.

Xen tries to make the exception registration process as fast as possible. Therefore, exception handling validation does not do safety checks such as verfiying that the handler code is present in memory (which could be expensive). As such, it could be the case that a guestOS invokes an exception handler which is not in memory, this is called a "double fault" (the program supposed to handle the exception faults as well). In such cases, Xen is capable of fecthing the appropriate handler for the guestOS. 

This kind of optimization can hardly go wrong with OSes the authors expect to handle, but one could imagine a malicious OS which would register an unusually high number of exception handlers which would cause double faults to occur much too often.### Section 4 : VAX / VMS An example of lazy evaluation in the VAX/VMS system is lazy zeroing of pages. When a process requires a fresh page of memory, than the OS maps a new page to the process address space, pretending that the page is available in ready, when in fact all it does is add an entry to the process page table marked as inaccessible. When the user attempts to read or write that page, an OS trap takes place. It is only then that the OS maps a physical memory page to that table entry and fills it with zeros. 
This optimization in cases where processes often demand more memory than is necessary, and end up with pages they don't read. If all pages requested by processes were actually read/written to, then lazy zeroing would be a poor choice of optimization.